{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCvuqaKH-8fQ",
        "outputId": "35885e04-f0dd-45f1-aca9-6d9cefb4ec63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.8)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.131)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.8->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.8->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.8->langchain) (3.0.0)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai pydantic\n",
        "!pip install -qU langchain-openai\n",
        "!pip install -qU pydantic\n",
        "%pip install --upgrade --quiet langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "fXP0jMz-BTqQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Define the Joke Function Using Pydantic\n",
        "\n",
        "We'll define a Joke model using Pydantic, which will represent the structure of the joke function."
      ],
      "metadata": {
        "id": "SjrmyAqk_Afk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field, field_validator\n",
        "\n",
        "# Define the joke tool using Pydantic\n",
        "class Joke(BaseModel):\n",
        "    \"\"\"Joke to tell the user.\"\"\"\n",
        "    setup: str = Field(description=\"Question to set up a joke\")\n",
        "    punchline: str = Field(description=\"Answer to resolve the joke\")\n",
        "\n",
        "    # Custom validation: Ensure the setup ends with a question mark\n",
        "    @field_validator(\"setup\")\n",
        "    def question_ends_with_question_mark(cls, value):\n",
        "        if not value.endswith(\"?\"):\n",
        "            raise ValueError(\"The setup must be a question ending with '?'!\")\n",
        "        return value\n"
      ],
      "metadata": {
        "id": "thfLcUIT_FzB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbXLdp6v_bd6",
        "outputId": "1a97a10a-4e1e-4170-8f10-ed54e2e3b3ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Initialize the OpenAI Model with the Joke Function\n",
        "\n",
        "We will bind the Joke function to the gpt-3.5-turbo model. This allows the model to use the function calling API to output jokes in a structured format."
      ],
      "metadata": {
        "id": "FdS6JRTg_cYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize OpenAI model and bind the Joke function\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0).bind_tools([Joke])\n"
      ],
      "metadata": {
        "id": "K6JDpcZL_fYT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Create the ChatPromptTemplate\n",
        "\n",
        "We will now define a prompt template, which represents the system and user instructions that are passed to the model."
      ],
      "metadata": {
        "id": "NyPpkChw_lNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create a prompt template with system and user instructions\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"You are a helpful assistant.\"), (\"user\", \"{input}\")]\n",
        ")\n"
      ],
      "metadata": {
        "id": "3NFml4yy_pnk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Implement Different Output Parsers\n",
        "\n",
        "We'll start by using the JsonOutputToolsParser to extract the function's output in a structured JSON format. Later, we will explore the PydanticToolsParser.\n",
        "5.1 Using JsonOutputToolsParser"
      ],
      "metadata": {
        "id": "8a81STlJ_y1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
        "\n",
        "# Initialize the JSON parser\n",
        "parser = JsonOutputToolsParser()\n",
        "\n",
        "# Combine prompt, model, and parser into a chain\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# Run the chain to invoke the model with a joke request\n",
        "result = chain.invoke({\"input\": \"tell me a joke\"})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qEtjBOX_18K",
        "outputId": "393b77d2-a6b0-47f1-d67d-6adfd71915b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'args': {'setup': \"Why couldn't the bicycle stand up by itself?\", 'punchline': 'Because it was two tired!'}, 'type': 'Joke'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2 Adding the return_id=True Option\n",
        "\n",
        "If you want to include the tool call ID along with the result, you can modify the parser:"
      ],
      "metadata": {
        "id": "OmPEYGuM_70S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the JSON parser with return_id=True\n",
        "parser = JsonOutputToolsParser(return_id=True)\n",
        "\n",
        "# Combine everything into a chain\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# Run the chain again\n",
        "result = chain.invoke({\"input\": \"tell me a joke\"})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja6DeyA2AG6N",
        "outputId": "40a8eca4-1175-4337-f915-3ae5e60ab4ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'args': {'setup': \"Why couldn't the bicycle stand up by itself?\", 'punchline': 'Because it was two tired!'}, 'id': 'call_LIjaPLxygeWwaFFXhXXBPHqn', 'type': 'Joke'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.3 Using JsonOutputKeyToolsParser (Extracting Specific Keys)\n",
        "\n",
        "If you only want to extract the specific keys from the response (e.g., the setup and punchline), you can use the JsonOutputKeyToolsParser."
      ],
      "metadata": {
        "id": "CsT1TDyZAKhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
        "\n",
        "# Initialize the parser to extract only the \"Joke\" key\n",
        "parser = JsonOutputKeyToolsParser(key_name=\"Joke\")\n",
        "\n",
        "# Combine prompt, model, and parser into a chain\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# Run the chain\n",
        "result = chain.invoke({\"input\": \"tell me a joke\"})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "530aNfybAWFh",
        "outputId": "fd920191-57b7-4b62-bee2-d6764341deb4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'setup': \"Why couldn't the bicycle stand up by itself?\", 'punchline': 'Because it was two tired!'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Using PydanticToolsParser for Validation\n",
        "\n",
        "Lastly, let’s use the PydanticToolsParser to validate the function's output using the Joke model."
      ],
      "metadata": {
        "id": "oiLPuUmOAZnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
        "\n",
        "# Initialize the Pydantic parser with the Joke model\n",
        "parser = PydanticToolsParser(tools=[Joke])\n",
        "\n",
        "# Create the model chain\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# Run the chain\n",
        "result = chain.invoke({\"input\": \"tell me a joke\"})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDxX5_J6Ai8Z",
        "outputId": "ebb88301-8855-466b-d15f-b2b4a820842e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Joke(setup=\"Why couldn't the bicycle stand up by itself?\", punchline='Because it was two tired!')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i36LO4sKAof5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}